# rag_multi_example.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import OpenAI
from pptx import Presentation
from pypdf import PdfReader
from docx import Document
import os
import numpy as np
from dotenv import load_dotenv
import glob

# -------------------------------
# 1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# -------------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# -------------------------------
# 2ï¸âƒ£ FastAPI ì•± ìƒì„± & CORS ì„¤ì •
# -------------------------------
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://chatbot-backend-stbs.onrender.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -------------------------------
# 3ï¸âƒ£ ë¬¸ì„œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------
def load_pdf_text(file_path):
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
        if page.extract_text():
            text += page.extract_text() + "\n"
    return text

def load_ppt_text(file_path):
    prs = Presentation(file_path)
    text = ""
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
    return text

def load_docx_text(file_path):
    doc = Document(file_path)
    return "\n".join([p.text for p in doc.paragraphs])

# -------------------------------
# 4ï¸âƒ£ í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
# -------------------------------
def split_text(text, chunk_size=300):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

# -------------------------------
# 5ï¸âƒ£ ì„ë² ë”© ìƒì„± í•¨ìˆ˜
# -------------------------------
def get_embedding(text):
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

# -------------------------------
# 6ï¸âƒ£ ë¬¸ì„œ í´ë” ë¡œë“œ & ë²¡í„°í™”
# -------------------------------
def load_all_documents(folder_path="documents"):
    chunks = []
    # PDF
    for file in glob.glob(os.path.join(folder_path, "*.pdf")):
        print(f"ğŸ“„ Loading PDF: {file}")
        chunks.extend(split_text(load_pdf_text(file)))
    # PPTX
    for file in glob.glob(os.path.join(folder_path, "*.pptx")):
        print(f"ğŸ“Š Loading PPTX: {file}")
        chunks.extend(split_text(load_ppt_text(file)))
    # DOCX
    for file in glob.glob(os.path.join(folder_path, "*.docx")):
        print(f"ğŸ“ Loading DOCX: {file}")
        chunks.extend(split_text(load_docx_text(file)))
    return chunks

# ë¬¸ì„œ ë¡œë“œ & ë²¡í„° ìƒì„±
print("ğŸ“‚ ë¬¸ì„œ ë¡œë”© ì‹œì‘...")
chunks = load_all_documents("documents")  # documents í´ë” í•„ìš”
embeddings = [get_embedding(chunk) for chunk in chunks]
embeddings = np.array(embeddings)
print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ! ì´ {len(chunks)}ê°œ ì²­í¬ ë²¡í„°í™”")

# -------------------------------
# 7ï¸âƒ£ ê²€ìƒ‰ í•¨ìˆ˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
# -------------------------------
def search(query, top_k=3):
    query_emb = np.array(get_embedding(query))
    similarities = np.dot(embeddings, query_emb) / (
        np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_emb)
    )
    top_indices = np.argsort(similarities)[::-1][:top_k]
    return [chunks[i] for i in top_indices]

# -------------------------------
# 8ï¸âƒ£ ì±—ë´‡ API
# -------------------------------
@app.post("/chat")
async def chat(user_input: dict):
    query = user_input.get("message", "")
    if not query.strip():
        return JSONResponse(content={"reply": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

    # ë¬¸ì„œ ê²€ìƒ‰
    context = search(query)

    # GPTì—ê²Œ ë¬¸ë§¥ê³¼ í•¨ê»˜ ì „ë‹¬
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë‹µí•˜ëŠ” AIì•¼."},
            {"role": "user", "content": f"ë¬¸ì„œ ë‚´ìš©: {context}\n\nì§ˆë¬¸: {query}"}
        ]
    )

    answer = response.choices[0].message.content
    return {"reply": answer}

# -------------------------------
# 9ï¸âƒ£ ì„œë²„ ì‹¤í–‰ í™•ì¸ìš© ë£¨íŠ¸
# -------------------------------
@app.get("/")
def root():
    return {"message": "RAG ê¸°ë°˜ ì±—ë´‡ ì„œë²„ ì‹¤í–‰ ì¤‘ ğŸš€"}
